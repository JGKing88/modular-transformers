{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjack-g-king\u001b[0m (\u001b[33mmodular_transformers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jackking/.netrc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer, BatchEncoding, GPT2LMHeadModel, GPT2Config, GPT2ForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import torch as torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import wandb\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "path = \"/om2/user/jackking/modular_transformers/scripts/input_statistics/data\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.login(key=\"a338f755915cccd861b14f29bf68601d8e1ec2c9\")\n",
    "\n",
    "#set seed\n",
    "seed = 38\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(Dataset):\n",
    "    def __init__(self, inputs, attn_mask=None, labels=None):\n",
    "        #cast to tensors if not already tensors\n",
    "        if not torch.is_tensor(inputs):\n",
    "            inputs = torch.tensor(inputs)\n",
    "        if not torch.is_tensor(labels):\n",
    "            labels = torch.tensor(labels)\n",
    "        if attn_mask is not None and not torch.is_tensor(attn_mask):\n",
    "            attn_mask = torch.tensor(attn_mask)\n",
    "            \n",
    "        self.inputs = inputs\n",
    "        self.attn_mask = attn_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is None:\n",
    "            item = {\n",
    "                'input_ids': self.inputs[idx],\n",
    "                'attention_mask': self.attn_mask[idx]}\n",
    "        elif self.attn_mask is None:\n",
    "            item = {\n",
    "                'input_ids': self.inputs[idx],\n",
    "                'labels': self.labels[idx]\n",
    "            }\n",
    "        else:\n",
    "            item = {\n",
    "                'input_ids': self.inputs[idx],\n",
    "                'attention_mask': self.attn_mask[idx],\n",
    "                'labels': self.labels[idx]\n",
    "            }\n",
    "        return item\n",
    "\n",
    "def make_autoregressive_dataset(data):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    dataset = tokenizer.batch_encode_plus(data, add_special_tokens=True, padding='longest', return_tensors=\"pt\")\n",
    "    inputs = dataset[\"input_ids\"]\n",
    "    attn_mask = dataset[\"attention_mask\"]\n",
    "    labels = dataset[\"input_ids\"].clone()\n",
    "    context_len = inputs.size(1)\n",
    "    return LMDataset(inputs, attn_mask, labels), context_len\n",
    "\n",
    "def make_classification_dataset(data1, data2):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    len1 = len(data1)\n",
    "    len2 = len(data2)\n",
    "    combined = data1 + data2\n",
    "    labels = [0]*len1 + [1]*len2\n",
    "    dataset = tokenizer.batch_encode_plus(combined, add_special_tokens=True, padding='longest', return_tensors=\"pt\")\n",
    "    inputs = dataset[\"input_ids\"]\n",
    "    attn_mask = dataset[\"attention_mask\"]\n",
    "    context_len = inputs.size(1)\n",
    "    return LMDataset(inputs, attn_mask, torch.tensor(labels)), context_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(data):\n",
    "    blah = []\n",
    "    for sent in data:\n",
    "        blah.extend(sent)\n",
    "    vocab_size = len(set(blah))\n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"experiment_1\"\n",
    "\n",
    "train_data = pickle.load(open(f\"{path}/{datatype}/train_data_A.pkl\", 'rb'))\n",
    "valid_data = pickle.load(open(f\"{path}/{datatype}/valid_data_A.pkl\", 'rb'))\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+valid_data)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(valid_data, labels=valid_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "train_data_B1 = pickle.load(open(f\"{path}/{datatype}/train_data_B1.pkl\", \"rb\"))\n",
    "val_data_B1 = pickle.load(open(f\"{path}/{datatype}/valid_data_B1.pkl\", \"rb\"))\n",
    "train_data_B2 = pickle.load(open(f\"{path}/{datatype}/train_data_B2.pkl\", \"rb\"))\n",
    "val_data_B2 = pickle.load(open(f\"{path}/{datatype}/valid_data_B2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_B1 + train_data_B2\n",
    "val_data = val_data_B1 + val_data_B2\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(val_data, labels=val_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M2_B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "train_data_T1 = pickle.load(open(f\"{path}/{datatype}/train_data_T1.pkl\", \"rb\"))\n",
    "val_data_T1 = pickle.load(open(f\"{path}/{datatype}/valid_data_T1.pkl\", \"rb\"))\n",
    "train_data_T2 = pickle.load(open(f\"{path}/{datatype}/train_data_T2.pkl\", \"rb\"))\n",
    "val_data_T2 = pickle.load(open(f\"{path}/{datatype}/valid_data_T2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_T1 + train_data_T2\n",
    "val_data = val_data_T1 + val_data_T2\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(val_data, labels=val_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M2_T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "train_data_T1 = pickle.load(open(f\"{path}/{datatype}/train_data_F1.pkl\", \"rb\"))\n",
    "val_data_T1 = pickle.load(open(f\"{path}/{datatype}/valid_data_F1.pkl\", \"rb\"))\n",
    "train_data_T2 = pickle.load(open(f\"{path}/{datatype}/train_data_F2.pkl\", \"rb\"))\n",
    "val_data_T2 = pickle.load(open(f\"{path}/{datatype}/valid_data_F2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_T1 #+ train_data_T2\n",
    "val_data = val_data_T1 #+ val_data_T2\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(val_data, labels=val_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M2_F1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "datatype = \"longer_data\"\n",
    "train_data_B1 = pickle.load(open(f\"{path}/{datatype}/train_data_B1.pkl\", \"rb\"))\n",
    "val_data_B1 = pickle.load(open(f\"{path}/{datatype}/valid_data_B1.pkl\", \"rb\"))\n",
    "train_data_B2 = pickle.load(open(f\"{path}/{datatype}/train_data_B2.pkl\", \"rb\"))\n",
    "val_data_B2 = pickle.load(open(f\"{path}/{datatype}/valid_data_B2.pkl\", \"rb\"))\n",
    "\n",
    "len1 = len(train_data_B1)\n",
    "len2 = len(train_data_B2)\n",
    "train_data = train_data_B1 + train_data_B2\n",
    "train_labels = [0]*len1 + [1]*len2\n",
    "val_data = val_data_B1 + val_data_B2\n",
    "len1 = len(val_data_B1)\n",
    "len2 = len(val_data_B2)\n",
    "val_labels = [0]*len1 + [1]*len2\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "\n",
    "trainset = LMDataset(train_data, labels=torch.tensor(train_labels))\n",
    "valset = LMDataset(val_data, labels=torch.tensor(val_labels))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model_type = \"M3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"longer_data\"\n",
    "train_data_T1 = pickle.load(open(f\"{path}/{datatype}/train_data_T1.pkl\", \"rb\"))\n",
    "val_data_T1 = pickle.load(open(f\"{path}/{datatype}/valid_data_T1.pkl\", \"rb\"))\n",
    "train_data_T2 = pickle.load(open(f\"{path}/{datatype}/train_data_T2.pkl\", \"rb\"))\n",
    "val_data_T2 = pickle.load(open(f\"{path}/{datatype}/valid_data_T2.pkl\", \"rb\"))\n",
    "\n",
    "len1 = len(train_data_T1)\n",
    "len2 = len(train_data_T2)\n",
    "train_data = train_data_T1 + train_data_T2\n",
    "train_labels = [0]*len1 + [1]*len2\n",
    "val_data = val_data_T1 + val_data_T2\n",
    "len1 = len(val_data_T1)\n",
    "len2 = len(val_data_T2)\n",
    "val_labels = [0]*len1 + [1]*len2\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "\n",
    "trainset = LMDataset(train_data, labels=torch.tensor(train_labels))\n",
    "valset = LMDataset(val_data, labels=torch.tensor(val_labels))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model_type = \"M3_T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"longer_data\"\n",
    "train_data_T1 = pickle.load(open(f\"{path}/{datatype}/train_data_F1.pkl\", \"rb\"))\n",
    "val_data_T1 = pickle.load(open(f\"{path}/{datatype}/valid_data_F1.pkl\", \"rb\"))\n",
    "train_data_T2 = pickle.load(open(f\"{path}/{datatype}/train_data_F2.pkl\", \"rb\"))\n",
    "val_data_T2 = pickle.load(open(f\"{path}/{datatype}/valid_data_F2.pkl\", \"rb\"))\n",
    "\n",
    "len1 = len(train_data_T1)\n",
    "len2 = len(train_data_T2)\n",
    "train_data = train_data_T1 + train_data_T2\n",
    "train_labels = [0]*len1 + [1]*len2\n",
    "val_data = val_data_T1 + val_data_T2\n",
    "len1 = len(val_data_T1)\n",
    "len2 = len(val_data_T2)\n",
    "val_labels = [0]*len1 + [1]*len2\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "\n",
    "trainset = LMDataset(train_data, labels=torch.tensor(train_labels))\n",
    "valset = LMDataset(val_data, labels=torch.tensor(val_labels))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model_type = \"M3_F\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacategory = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = f\"experiment_2S_{datacategory}\"\n",
    "data_path = f\"{path}/experiment_2S\"\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_data = pickle.load(open(f\"{data_path}/train_data_{datacategory}.pkl\", 'rb'))\n",
    "valid_data = pickle.load(open(f\"{data_path}/valid_data_{datacategory}.pkl\", 'rb'))\n",
    "\n",
    "vocab_size = get_vocab_size(train_data[\"inputs\"]+valid_data[\"inputs\"])\n",
    "\n",
    "ctx_len = len(train_data[\"inputs\"][0])\n",
    "\n",
    "trainset = LMDataset(train_data[\"inputs\"], labels=train_data[\"inputs\"])\n",
    "valset = LMDataset(valid_data[\"inputs\"], labels=valid_data[\"inputs\"])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = f\"experiment_2_{datacategory}\"\n",
    "data_path = f\"{path}/experiment_2\"\n",
    "\n",
    "train_data = pickle.load(open(f\"{data_path}/train_data_{datacategory}.pkl\", 'rb'))\n",
    "valid_data = pickle.load(open(f\"{data_path}/valid_data_{datacategory}.pkl\", 'rb'))\n",
    "\n",
    "ctx_len = len(train_data[\"inputs\"][0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data[\"inputs\"] + valid_data[\"inputs\"])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_labels = 200\n",
    "\n",
    "trainset = LMDataset(train_data[\"inputs\"], labels=train_data[\"labels\"])\n",
    "valset = LMDataset(valid_data[\"inputs\"], labels=valid_data[\"labels\"])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in tqdm(enumerate(valloader), total=len(valloader)):\n",
    "        with torch.no_grad():\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            if \"attention_mask\" in batch:\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            else:\n",
    "                attention_mask = None\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(inputs, labels=labels, attention_mask=attention_mask)\n",
    "        losses.append(outputs.loss)\n",
    "    loss = torch.mean(torch.stack(losses))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader):\n",
    "    wandb.init(project=\"input statistics\", config=train_config)\n",
    "    run_name = wandb.run.name\n",
    "\n",
    "    save_epochs = train_config[\"num_epochs\"] // 10\n",
    "    save_epochs = 1\n",
    "\n",
    "    for epoch in tqdm(range(train_config[\"num_epochs\"])):\n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        for step, batch in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            if \"attention_mask\" in batch:\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            else:\n",
    "                attention_mask = None\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # print(inputs[0], labels[0])\n",
    "\n",
    "            outputs = model(inputs, labels=labels, attention_mask=attention_mask)\n",
    "            loss = outputs.loss \n",
    "            loss.backward()\n",
    "            if train_config[\"lr_scheduler\"] is not None:\n",
    "                lr_scheduler.step()\n",
    "            optimizer.step()\n",
    "\n",
    "            wandb.log({\"step\": step + len(trainloader) * epoch})\n",
    "            wandb.log({\"loss\": loss.item()})\n",
    "            wandb.log({\"learning_rate\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "        wandb.log({\"epoch\": epoch})\n",
    "        val_loss = evaluate(model, valloader)\n",
    "        wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "        #save model\n",
    "        if epoch % save_epochs == 0:\n",
    "            model_dir = os.path.join(path, model_name, run_name, f\"epoch_{epoch}\")\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            model.save_pretrained(model_dir)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    #save model\n",
    "    model_dir = os.path.join(path, model_name, run_name, \"final_chkpoint\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/vast-storage/scratch/vast/evlab/jackking/modular_transformers/modular_transformers/train/wandb/run-20240617_184147-llwm9cq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modular_transformers/input%20statistics/runs/llwm9cq3' target=\"_blank\">fiery-bee-484</a></strong> to <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/llwm9cq3' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/llwm9cq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.41it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.28it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.23it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.20it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.11it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.12it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.11it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.36it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.13it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.13it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.18it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.18it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.18it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.17it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 50/50 [14:53<00:00, 17.86s/it]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▆▆▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>loss</td><td>0.64896</td></tr><tr><td>step</td><td>5899</td></tr><tr><td>val_loss</td><td>0.64514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fiery-bee-484</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/llwm9cq3' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/llwm9cq3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240617_184147-llwm9cq3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "n_layer = 12\n",
    "n_head = 4\n",
    "resid_pdrop = 0.1\n",
    "embd_pdrop = 0.2\n",
    "attn_pdrop = 0.2\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "vocab_size = vocab_size + 5 #for special tokens\n",
    "num_labels = 200\n",
    "\n",
    "model_config = GPT2Config(n_layer = n_layer, n_head = n_head, n_embd = embedding_dim, n_positions = ctx_len, #vocab_size = vocab_size,\n",
    "                          resid_pdrop=resid_pdrop, embd_pdrop=embd_pdrop, attn_pdrop=attn_pdrop, num_labels=num_labels\n",
    "                          )\n",
    "# model = GPT2ForSequenceClassification._from_config(model_config)\n",
    "model = GPT2LMHeadModel._from_config(model_config)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "model_name = f\"{datatype}/{model_type}_{embedding_dim}_{n_layer}\"\n",
    "train_config = {\"num_epochs\": 50, \"lr\": 0.0001, \"lr_scheduler\": lr_scheduler, \"batch_size\": batch_size, \"resid_pdrop\": resid_pdrop, \"embd_pdrop\": embd_pdrop, \"n_head\": n_head,\n",
    "                \"attn_pdrop\": attn_pdrop, \"model_name\": model_name, \"model_type\": model_type, \"embedding_dim\": embedding_dim, \"n_layer\": n_layer, \"ctx_len\": ctx_len, \"datatype\": datatype}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"])\n",
    "if train_config[\"lr_scheduler\"] is not None:\n",
    "    if train_config[\"lr_scheduler\"] == \"cosine_annealing\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"]*30)\n",
    "    elif train_config[\"lr_scheduler\"] == \"cosine\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"] * len(trainloader))\n",
    "    elif train_config[\"lr_scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.98)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/vast-storage/scratch/vast/evlab/jackking/modular_transformers/modular_transformers/train/wandb/run-20240613_185802-9mltbnfn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modular_transformers/input%20statistics/runs/9mltbnfn' target=\"_blank\">olive-wildflower-467</a></strong> to <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/9mltbnfn' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/9mltbnfn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n",
      "100%|██████████| 157/157 [00:13<00:00, 12.03it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.61it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.58it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.63it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.61it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.63it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.59it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.58it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.72it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.62it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.58it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.72it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.46it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.58it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.73it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.48it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.61it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.09it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.60it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.74it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.63it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.73it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.73it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.68it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.49it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.55it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.63it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.66it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.65it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.67it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.74it/s]\n",
      "100%|██████████| 200/200 [34:13<00:00, 10.27s/it]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>step</td><td>31399</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-wildflower-467</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/9mltbnfn' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/9mltbnfn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_185802-9mltbnfn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "datacategory = \"EB\"\n",
    "\n",
    "train_data_1 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}1.pkl\", \"rb\"))\n",
    "val_data_1 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}1.pkl\", \"rb\"))\n",
    "train_data_2 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}2.pkl\", \"rb\"))\n",
    "val_data_2 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_1 + train_data_2\n",
    "val_data = val_data_1 + val_data_2\n",
    "\n",
    "len1 = len(train_data_1)\n",
    "len2 = len(train_data_2)\n",
    "train_labels = [0]*len1 + [1]*len2\n",
    "len1 = len(val_data_1)\n",
    "len2 = len(val_data_2)\n",
    "val_labels = [0]*len1 + [1]*len2\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "\n",
    "trainset = LMDataset(train_data, labels=torch.tensor(train_labels))\n",
    "valset = LMDataset(val_data, labels=torch.tensor(val_labels))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model_type = f\"M3_{datacategory}\"\n",
    "\n",
    "embedding_dim = 128\n",
    "n_layer = 12\n",
    "n_head = 4\n",
    "resid_pdrop = 0.1\n",
    "embd_pdrop = 0.3\n",
    "attn_pdrop = 0.3\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "num_labels = 2\n",
    "\n",
    "model_config = GPT2Config(n_layer = n_layer, n_head = n_head, n_embd = embedding_dim, n_positions = ctx_len, #vocab_size = vocab_size,\n",
    "                          resid_pdrop=resid_pdrop, embd_pdrop=embd_pdrop, attn_pdrop=attn_pdrop, num_labels=num_labels\n",
    "                          )\n",
    "model = GPT2ForSequenceClassification._from_config(model_config)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "model_name = f\"{datatype}/{model_type}_{embedding_dim}_{n_layer}\"\n",
    "train_config = {\"num_epochs\": 200, \"lr\": 0.000005, \"lr_scheduler\": lr_scheduler, \"batch_size\": batch_size, \"resid_pdrop\": resid_pdrop, \"embd_pdrop\": embd_pdrop, \"n_head\": n_head,\n",
    "                \"attn_pdrop\": attn_pdrop, \"model_name\": model_name, \"model_type\": model_type, \"embedding_dim\": embedding_dim, \"n_layer\": n_layer, \"ctx_len\": ctx_len, \"datatype\": datatype}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"])\n",
    "if train_config[\"lr_scheduler\"] is not None:\n",
    "    if train_config[\"lr_scheduler\"] == \"cosine_annealing\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"]*30)\n",
    "    elif train_config[\"lr_scheduler\"] == \"cosine\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"] * len(trainloader))\n",
    "    elif train_config[\"lr_scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.98)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3152utfg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▄▂▂▃▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▄▁▃▁▂▂█▁▁▂▁▁▃▂▂▂▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>loss</td><td>0.00378</td></tr><tr><td>step</td><td>3037</td></tr><tr><td>val_loss</td><td>0.19453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-tree-477</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/3152utfg' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/3152utfg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240614_141916-3152utfg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3152utfg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/vast-storage/scratch/vast/evlab/jackking/modular_transformers/modular_transformers/train/wandb/run-20240614_142306-kwh3p72n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kwh3p72n' target=\"_blank\">dashing-firefly-479</a></strong> to <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kwh3p72n' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/kwh3p72n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.43it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.42it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.44it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.42it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.98it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.07it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.25it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.28it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.30it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.12it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.78it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.29it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.24it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.27it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.25it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.29it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.37it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.21it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.81it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.06it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.14it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.42it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.23it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.55it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.51it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.94it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.41it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.44it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.42it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.31it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.50it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.44it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.30it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.30it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.43it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.47it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.94it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.30it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.45it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.02it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.39it/s]\n",
      "100%|██████████| 300/300 [51:28<00:00, 10.30s/it]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>299</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>step</td><td>47099</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-firefly-479</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kwh3p72n' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/kwh3p72n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240614_142306-kwh3p72n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "datacategory = \"EB\"\n",
    "\n",
    "train_data_1 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}1.pkl\", \"rb\"))\n",
    "val_data_1 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}1.pkl\", \"rb\"))\n",
    "train_data_2 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}2.pkl\", \"rb\"))\n",
    "val_data_2 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_1 + train_data_2\n",
    "val_data = val_data_1 + val_data_2\n",
    "\n",
    "len1 = len(train_data_1)\n",
    "len2 = len(train_data_2)\n",
    "train_labels = [0]*len1 + [1]*len2\n",
    "len1 = len(val_data_1)\n",
    "len2 = len(val_data_2)\n",
    "val_labels = [0]*len1 + [1]*len2\n",
    "\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "\n",
    "trainset = LMDataset(train_data, labels=torch.tensor(train_labels))\n",
    "valset = LMDataset(val_data, labels=torch.tensor(val_labels))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model_type = f\"M3_{datacategory}\"\n",
    "\n",
    "embedding_dim = 128\n",
    "n_layer = 12\n",
    "n_head = 4\n",
    "resid_pdrop = 0.1\n",
    "embd_pdrop = 0.3\n",
    "attn_pdrop = 0.3\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "num_labels = 2\n",
    "\n",
    "model_config = GPT2Config(n_layer = n_layer, n_head = n_head, n_embd = embedding_dim, n_positions = ctx_len, #vocab_size = vocab_size,\n",
    "                          resid_pdrop=resid_pdrop, embd_pdrop=embd_pdrop, attn_pdrop=attn_pdrop, num_labels=num_labels\n",
    "                          )\n",
    "model = GPT2ForSequenceClassification._from_config(model_config)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "model_name = f\"{datatype}/{model_type}_{embedding_dim}_{n_layer}\"\n",
    "train_config = {\"num_epochs\": 300, \"lr\": 0.000005, \"lr_scheduler\": lr_scheduler, \"batch_size\": batch_size, \"resid_pdrop\": resid_pdrop, \"embd_pdrop\": embd_pdrop, \"n_head\": n_head,\n",
    "                \"attn_pdrop\": attn_pdrop, \"model_name\": model_name, \"model_type\": model_type, \"embedding_dim\": embedding_dim, \"n_layer\": n_layer, \"ctx_len\": ctx_len, \"datatype\": datatype}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"])\n",
    "if train_config[\"lr_scheduler\"] is not None:\n",
    "    if train_config[\"lr_scheduler\"] == \"cosine_annealing\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"]*30)\n",
    "    elif train_config[\"lr_scheduler\"] == \"cosine\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"] * len(trainloader))\n",
    "    elif train_config[\"lr_scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.98)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/vast-storage/scratch/vast/evlab/jackking/modular_transformers/modular_transformers/train/wandb/run-20240613_032115-kp9a4da5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kp9a4da5' target=\"_blank\">twilight-vortex-462</a></strong> to <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kp9a4da5' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/kp9a4da5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.62it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.47it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.58it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.47it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.52it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.46it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.52it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.46it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.49it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.46it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.46it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.46it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.45it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.45it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.45it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.42it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████| 118/118 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.40it/s]\n",
      "100%|██████████| 150/150 [44:02<00:00, 17.61s/it]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▇▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>149</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>loss</td><td>0.62149</td></tr><tr><td>step</td><td>17699</td></tr><tr><td>val_loss</td><td>0.6465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-vortex-462</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/kp9a4da5' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/kp9a4da5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_032115-kp9a4da5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "datacategory = \"EB\"\n",
    "\n",
    "train_data_1 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}1.pkl\", \"rb\"))\n",
    "val_data_1 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}1.pkl\", \"rb\"))\n",
    "train_data_2 = pickle.load(open(f\"{path}/{datatype}/train_data_{datacategory}2.pkl\", \"rb\"))\n",
    "val_data_2 = pickle.load(open(f\"{path}/{datatype}/valid_data_{datacategory}2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_1 + train_data_2\n",
    "val_data = val_data_1 + val_data_2\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(val_data, labels=val_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = f\"M2_{datacategory}\"\n",
    "\n",
    "embedding_dim = 128\n",
    "n_layer = 12\n",
    "n_head = 4\n",
    "resid_pdrop = 0.1\n",
    "embd_pdrop = 0.2\n",
    "attn_pdrop = 0.2\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "num_labels = 200\n",
    "\n",
    "model_config = GPT2Config(n_layer = n_layer, n_head = n_head, n_embd = embedding_dim, n_positions = ctx_len, #vocab_size = vocab_size,\n",
    "                          resid_pdrop=resid_pdrop, embd_pdrop=embd_pdrop, attn_pdrop=attn_pdrop, num_labels=num_labels\n",
    "                          )\n",
    "# model = GPT2ForSequenceClassification._from_config(model_config)\n",
    "model = GPT2LMHeadModel._from_config(model_config)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "model_name = f\"{datatype}/{model_type}_{embedding_dim}_{n_layer}\"\n",
    "train_config = {\"num_epochs\": 150, \"lr\": 0.0001, \"lr_scheduler\": lr_scheduler, \"batch_size\": batch_size, \"resid_pdrop\": resid_pdrop, \"embd_pdrop\": embd_pdrop, \"n_head\": n_head,\n",
    "                \"attn_pdrop\": attn_pdrop, \"model_name\": model_name, \"model_type\": model_type, \"embedding_dim\": embedding_dim, \"n_layer\": n_layer, \"ctx_len\": ctx_len, \"datatype\": datatype}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"])\n",
    "if train_config[\"lr_scheduler\"] is not None:\n",
    "    if train_config[\"lr_scheduler\"] == \"cosine_annealing\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"]*30)\n",
    "    elif train_config[\"lr_scheduler\"] == \"cosine\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"] * len(trainloader))\n",
    "    elif train_config[\"lr_scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.98)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datatype = \"experiment_1\"\n",
    "train_data_T1 = pickle.load(open(f\"{path}/{datatype}/train_data_F1.pkl\", \"rb\"))\n",
    "val_data_T1 = pickle.load(open(f\"{path}/{datatype}/valid_data_F1.pkl\", \"rb\"))\n",
    "train_data_T2 = pickle.load(open(f\"{path}/{datatype}/train_data_F2.pkl\", \"rb\"))\n",
    "val_data_T2 = pickle.load(open(f\"{path}/{datatype}/valid_data_F2.pkl\", \"rb\"))\n",
    "\n",
    "train_data = train_data_T1 + train_data_T2\n",
    "val_data = val_data_T1 + val_data_T2\n",
    "\n",
    "vocab_size = get_vocab_size(train_data+val_data)\n",
    "ctx_len = len(train_data[0])\n",
    "\n",
    "trainset = LMDataset(train_data, labels=train_data)\n",
    "valset = LMDataset(val_data, labels=val_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_type = \"M2_F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/vast-storage/scratch/vast/evlab/jackking/modular_transformers/modular_transformers/train/wandb/run-20240612_193757-pgv4msn1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modular_transformers/input%20statistics/runs/pgv4msn1' target=\"_blank\">dainty-brook-452</a></strong> to <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modular_transformers/input%20statistics' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/pgv4msn1' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/pgv4msn1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.28it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.29it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.41it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.41it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.25it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.29it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.29it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.38it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.30it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.39it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.31it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████| 100/100 [38:18<00:00, 22.99s/it]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>loss</td><td>3.18818</td></tr><tr><td>step</td><td>15699</td></tr><tr><td>val_loss</td><td>4.42785</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-brook-452</strong> at: <a href='https://wandb.ai/modular_transformers/input%20statistics/runs/pgv4msn1' target=\"_blank\">https://wandb.ai/modular_transformers/input%20statistics/runs/pgv4msn1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240612_193757-pgv4msn1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "n_layer = 12\n",
    "n_head = 4\n",
    "resid_pdrop = 0.1\n",
    "embd_pdrop = 0.2\n",
    "attn_pdrop = 0.2\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "num_labels = 200\n",
    "\n",
    "model_config = GPT2Config(n_layer = n_layer, n_head = n_head, n_embd = embedding_dim, n_positions = ctx_len, #vocab_size = vocab_size,\n",
    "                          resid_pdrop=resid_pdrop, embd_pdrop=embd_pdrop, attn_pdrop=attn_pdrop, num_labels=num_labels\n",
    "                          )\n",
    "# model = GPT2ForSequenceClassification._from_config(model_config)\n",
    "model = GPT2LMHeadModel._from_config(model_config)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "model_name = f\"{datatype}/{model_type}_{embedding_dim}_{n_layer}\"\n",
    "train_config = {\"num_epochs\": 100, \"lr\": 0.001, \"lr_scheduler\": lr_scheduler, \"batch_size\": batch_size, \"resid_pdrop\": resid_pdrop, \"embd_pdrop\": embd_pdrop, \"n_head\": n_head,\n",
    "                \"attn_pdrop\": attn_pdrop, \"model_name\": model_name, \"model_type\": model_type, \"embedding_dim\": embedding_dim, \"n_layer\": n_layer, \"ctx_len\": ctx_len, \"datatype\": datatype}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"])\n",
    "if train_config[\"lr_scheduler\"] is not None:\n",
    "    if train_config[\"lr_scheduler\"] == \"cosine_annealing\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"]*30)\n",
    "    elif train_config[\"lr_scheduler\"] == \"cosine\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_config[\"num_epochs\"] * len(trainloader))\n",
    "    elif train_config[\"lr_scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.98)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_config, model_name, trainloader, valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
