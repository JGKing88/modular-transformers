{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/om/weka/evlab/ehoseini/MyData/miniBERTa_v2/'\n",
    "# grouped_pad_valid = load_from_disk(\n",
    "#     os.path.join(path, f'miniBERTa-100M-crunched',\n",
    "#                     f'valid_context_len_{1024}'))\n",
    "\n",
    "# eval_dataloader = DataLoader(grouped_pad_valid, shuffle=False, batch_size=32)\n",
    "# del grouped_pad_valid\n",
    "\n",
    "# model_names = [\"768-768-768-128-128-768-768-768\", \"768-768-768-768-768-768-768-768\", \"768-768-768-128-768-768-768\", \"768-768-768-768-768-768-768\", \"768-768-768-576-768-768-768\"]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/reg_loss/checkpoint_72000'\n",
    "#     try:\n",
    "#         model = components.LM.from_pretrained(path)\n",
    "#     except:\n",
    "#         print(\"Failed to load model \", model_name)\n",
    "#         continue\n",
    "#     model = model.to(device)\n",
    "#     print(evaluate(model, eval_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/rdma/vast-rdma/vast/evlab/ehoseini/MyData/sent_sampling/analysis/straightening/generation/sentences_ud_sentencez_token_filter_v3_textNoPeriod_cntx_3_cont_7.pkl\"\n",
    "# with open(data_dir, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# data = tokenizer.batch_encode_plus(data, add_special_tokens=True, pad_to_max_length=False, return_tensors=\"np\")[\"input_ids\"]\n",
    "\n",
    "# bottleneck_dict = {}\n",
    "\n",
    "# model_names = [\"768-768-768-128-128-768-768-768\", \"768-768-768-768-768-768-768-768\", \"768-768-768-576-576-768-768-768\", \"768-768-768-256-256-768-768-768\", \"768-768-768-960-960-768-768-768\", \"768-768-768-384-384-768-768-768\"]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     # path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/checkpoint_final'\n",
    "#     path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/reg_loss/checkpoint_72000'\n",
    "#     try:\n",
    "#         model = components.LM.from_pretrained(path)\n",
    "#     except:\n",
    "#         print(\"Failed to load model \", model_name)\n",
    "#         continue\n",
    "    \n",
    "#     model.to(device)\n",
    "#     activations = compute_model_activations(model, data, device)\n",
    "#     one_curvature_dict = compute_model_curvature(activations)\n",
    "#     bottleneck_dict[model_name] = one_curvature_dict\n",
    "#     curve = 180 / np.pi * one_curvature_dict[\"curve\"]\n",
    "#     plt.plot(np.nanmean(curve, axis=1), label=model_name)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# model_names = [\"768-768-768-128-768-768-768\", \"768-768-768-768-768-768-768\", \"768-768-768-576-768-768-768\",  \"768-768-768-384-768-768-768\",  \"768-768-768-960-768-768-768\",  \"768-768-768-256-768-768-768\"]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     # path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/checkpoint_final'\n",
    "#     path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/reg_loss/checkpoint_72000'\n",
    "#     try:\n",
    "#         model = components.LM.from_pretrained(path)\n",
    "#     except:\n",
    "#         print(\"Failed to load model \", model_name)\n",
    "#         continue\n",
    "    \n",
    "#     model.to(device)\n",
    "#     activations = compute_model_activations(model, data, device)\n",
    "#     one_curvature_dict = compute_model_curvature(activations)\n",
    "#     bottleneck_dict[model_name] = one_curvature_dict\n",
    "#     curve = 180 / np.pi * one_curvature_dict[\"curve\"]\n",
    "#     plt.plot(np.nanmean(curve, axis=1), label=model_name)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# model_names = [\"768-768-128-128-768-768\", \"768-768-768-768-768-768\", \"768-768-576-576-768-768\", \"768-768-256-256-768-768\", \"768-768-960-960-768-768\", \"768-768-384-384-768-768\"]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     # path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/checkpoint_final'\n",
    "#     path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/reg_loss/checkpoint_72000'\n",
    "#     try:\n",
    "#         model = components.LM.from_pretrained(path)\n",
    "#     except:\n",
    "#         print(\"Failed to load model \", model_name)\n",
    "#         continue\n",
    "    \n",
    "#     model.to(device)\n",
    "#     activations = compute_model_activations(model, data, device)\n",
    "#     one_curvature_dict = compute_model_curvature(activations)\n",
    "#     bottleneck_dict[model_name] = one_curvature_dict\n",
    "#     curve = 180 / np.pi * one_curvature_dict[\"curve\"]\n",
    "#     plt.plot(np.nanmean(curve, axis=1), label=model_name)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# model_names = [\"768-768-128-768-768\", \"768-768-768-768-768\", \"768-768-576-768-768\",  \"768-768-384-768-768\",  \"768-768-960-768-768\",  \"768-768-256-768-768\"]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     # path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/checkpoint_final'\n",
    "#     path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/reg_loss/checkpoint_72000'\n",
    "#     try:\n",
    "#         model = components.LM.from_pretrained(path)\n",
    "#     except:\n",
    "#         print(\"Failed to load model \", model_name)\n",
    "#         continue\n",
    "    \n",
    "#     model.to(device)\n",
    "#     activations = compute_model_activations(model, data, device)\n",
    "#     one_curvature_dict = compute_model_curvature(activations)\n",
    "#     bottleneck_dict[model_name] = one_curvature_dict\n",
    "#     curve = 180 / np.pi * one_curvature_dict[\"curve\"]\n",
    "#     plt.plot(np.nanmean(curve, axis=1), label=model_name)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for key, value in losses.items():\n",
    "#     if key in bottleneck_dict:\n",
    "#         lowest_curve = min(np.nanmean(180 / np.pi * bottleneck_dict[key][\"curve\"], axis=1))\n",
    "#         plt.scatter(lowest_curve, value, label=key)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# with open(\"bottleneck_dict.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(bottleneck_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = {'768-128-768': 3.5388755003611245,\n",
    "#  '768-768-128-128-768-768': 3.549605369567871,\n",
    "#  '768-768-128-768-768': 3.486420154571533,\n",
    "#  '768-768-768-128-128-768-768-768': 3.469570684432983,\n",
    "#  '768-768-768-128-768-768-768': 3.4118173122406006,\n",
    "#  '768-768-768-768-128-128-768-768-768-768': 3.5046932697296143,\n",
    "#  '768-256-768': 3.443772077560425,\n",
    "#  '768-768-256-256-768-768': 3.427821922302246,\n",
    "#  '768-768-256-768-768': 3.398317003250122,\n",
    "#  '768-768-768-256-256-768-768-768': 3.4572417736053467,\n",
    "#  '768-768-768-256-768-768-768': 3.4455856482187905,\n",
    "#  '768-768-768-768-256-256-768-768-768-768': 3.451516532897949,\n",
    "#  '768-384-768': 3.4109373092651367,\n",
    "#  '768-768-384-384-768-768': 3.414565849304199,\n",
    "#  '768-768-384-768-768': 3.41301953792572,\n",
    "#  '768-768-768-384-384-768-768-768': 3.426470136642456,\n",
    "#  '768-768-768-384-768-768-768': 3.4111345291137694,\n",
    "#  '768-576-768': 3.401872396469116,\n",
    "#  '768-768-576-576-768-768': 3.375704526901245,\n",
    "#  '768-768-576-768-768': 3.4097533226013184,\n",
    "#  '768-768-768-576-576-768-768-768': 3.4138837655385337,\n",
    "#  '768-768-768-576-768-768-768': 3.5351122617721558,\n",
    "#  '768-768-768-768-576-576-768-768-768-768': 3.4858854611714682,\n",
    "#  '768-768-768': 3.383584976196289,\n",
    "#  '768-768-768-768-768-768': 3.3486914237340293,\n",
    "#  '768-768-768-768-768': 3.4189711213111877,\n",
    "#  '768-768-768-768-768-768-768-768': 3.4119746685028076,\n",
    "#  '768-768-768-768-768-768-768': 3.425382435321808,\n",
    "#  '768-768-768-768-768-768-768-768-768-768': 3.4653550386428833,\n",
    "#  '768-960-768': 3.368660628795624,\n",
    "#  '768-768-960-960-768-768': 3.3299508094787598,\n",
    "#  '768-768-960-768-768': 3.40032696723938,\n",
    "#  '768-768-768-960-960-768-768-768': 3.4360488255818686,\n",
    "#  '768-768-768-960-768-768-768': 3.4985439777374268,\n",
    "#  '768-768-768-768-960-960-768-768-768-768': 3.50168514251709,\n",
    "#  '768-1152-768': 3.365297794342041,\n",
    "#  '768-768-1152-1152-768-768': 3.3653138279914856,\n",
    "#  '768-768-1152-768-768': 3.363027572631836,\n",
    "#  '768-768-768-1152-1152-768-768-768': 3.422353148460388,\n",
    "#  '768-768-768-1152-768-768-768': 3.45822024345398,\n",
    "#  '768-768-768-768-1152-1152-768-768-768-768': 3.4286587238311768}\n",
    "\n",
    "# for length in [5, 6, 7, 8]:\n",
    "#     print(len)\n",
    "#     for key, value in losses.items():\n",
    "#         if key in bottleneck_dict:\n",
    "#             if len(key.split(\"-\")) == length:\n",
    "#                 lowest_curve = np.mean(np.nanmean(180 / np.pi * bottleneck_dict[key][\"curve\"], axis=1))\n",
    "#                 plt.scatter(lowest_curve, value, label=key)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
