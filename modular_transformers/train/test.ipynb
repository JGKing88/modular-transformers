{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, set_seed\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from minicons import scorer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "from modular_transformers.straightening.straightening_utils import compute_model_activations, compute_model_curvature\n",
    "\n",
    "from modular_transformers.models import components\n",
    "from transformer_xray.perturb_utils import register_pertubation_hooks\n",
    "\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#set tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "fine_tuned_models = [\"finetuned-1-l2_curvature-768x12\", \"finetuned-1-l1_curvature-768x12\", \"huggingface-pretrained-768x12\", \"finetuned-1-l0_curvature-768x12\"]\n",
    "fulltrained_models = ['warmup5-lr0.0006-0.1-l0_curvature-768x12', 'multi-warmup5-lr0.0006-1-l2_curvature-768x12', 'warmup5-lr0.0006-1-l2_curvature-768x12','768x12_test']\n",
    "\n",
    "model_names = fine_tuned_models + fulltrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_pertubation(shape, pertubation_size):\n",
    "    pertubation = torch.randn(shape)\n",
    "    pertubation = pertubation / np.linalg.norm(pertubation) * pertubation_size\n",
    "    return pertubation\n",
    "\n",
    "def random_perturbation_function(input, layer, token):\n",
    "    size = np.linalg.norm(input) / 10\n",
    "    return generate_random_pertubation(input.shape, size)\n",
    "\n",
    "def compute_surprisals_with_context(model_names, prefixes, queries, perturbation_type, surprisal_type):\n",
    "    surprisal_dict = torch.load(\"/om2/user/jackking/modular_transformers/modular_transformers/train/surprisal_dict.pt\", map_location=torch.device('cpu'))\n",
    "    \n",
    "    if perturbation_type not in surprisal_dict:\n",
    "        surprisal_dict[perturbation_type] = {}\n",
    "    if surprisal_type not in surprisal_dict[perturbation_type]:\n",
    "        surprisal_dict[perturbation_type][surprisal_type] = {}\n",
    "\n",
    "    for model_name in tqdm(model_names):\n",
    "        print(model_name)\n",
    "        if model_name in surprisal_dict[perturbation_type][surprisal_type]:\n",
    "            continue\n",
    "        path = f'/om2/user/jackking/MyData/mt/miniberta_100M/{model_name}/checkpoint_final'\n",
    "        model = components.LM.from_pretrained(path)\n",
    "\n",
    "        if perturbation_type == \"activation\":\n",
    "            perturbation_hooks = {0: [(\"before_attn\", \"all\", random_perturbation_function)]}\n",
    "            register_pertubation_hooks(model, perturbation_hooks, device)\n",
    "\n",
    "        model = scorer.IncrementalLMScorer(model, tokenizer=tokenizer, device=device)\n",
    "        all_surprisals = []\n",
    "        for prefix, query in tqdm(zip(prefixes, queries)):\n",
    "            surprisals = model.conditional_score(prefix, query, reduction = lambda x: -x.sum(0))\n",
    "            all_surprisals.extend(surprisals)\n",
    "        surprisal_dict[perturbation_type][surprisal_type][model_name] = np.array(all_surprisals)\n",
    "\n",
    "    with open(\"/om2/user/jackking/modular_transformers/modular_transformers/train/surprisal_dict.pt\", 'wb') as f:\n",
    "        torch.save(surprisal_dict, f)\n",
    "\n",
    "def perturb_inputs(input_ids, perturbation_type):\n",
    "    perturbation_amount = math.ceil(len(input_ids) * 0.1)\n",
    "    if perturbation_type == \"swap\":\n",
    "        for i in range(perturbation_amount):\n",
    "            idx1, idx2 = np.random.choice(len(input_ids), 2)\n",
    "            input_ids[idx1], input_ids[idx2] = input_ids[idx2], input_ids[idx1]\n",
    "        return input_ids\n",
    "    elif perturbation_type == \"remove\":\n",
    "        for i in range(perturbation_amount):\n",
    "            idx = np.random.choice(len(input_ids))\n",
    "            input_ids[idx] = tokenizer.pad_token_id\n",
    "        return input_ids\n",
    "    elif perturbation_type == \"replace\":\n",
    "        for i in range(perturbation_amount):\n",
    "            idx = np.random.choice(len(input_ids))\n",
    "            input_ids[idx] = np.random.choice(len(tokenizer))\n",
    "        return input_ids\n",
    "    else:\n",
    "        raise ValueError(f\"perturbation_type {perturbation_type} not recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned-1-l2_curvature-768x12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/minicons/scorer.py:1213: UserWarning: tokenizer is changed by adding pad_token_id to the tokenizer.\n",
      "  warnings.warn(\n",
      "500it [05:28,  1.52it/s]\n",
      " 25%|██▌       | 1/4 [05:32<16:37, 332.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned-1-l1_curvature-768x12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:42,  1.77it/s]\n",
      " 50%|█████     | 2/4 [10:26<10:19, 309.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pretrained-768x12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [05:00,  1.67it/s]\n",
      " 75%|███████▌  | 3/4 [15:38<05:10, 310.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned-1-l0_curvature-768x12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:44,  1.76it/s]\n",
      "100%|██████████| 4/4 [20:34<00:00, 308.67s/it]\n"
     ]
    }
   ],
   "source": [
    "path = '/om/weka/evlab/ehoseini/MyData/miniBERTa_v2/'\n",
    "data_size = \"10M\"\n",
    "data = load_from_disk(\n",
    "    os.path.join(path, f'miniBERTa-{data_size}-crunched',\n",
    "                    f'train_context_len_{512}'))\n",
    "\n",
    "prefixes = [tokenizer.decode(sample[:20]) for sample in data[\"input_ids\"][:500]]\n",
    "queries = [tokenizer.decode(sample[20:40]) for sample in data[\"input_ids\"][:500]]\n",
    "\n",
    "compute_surprisals_with_context(fine_tuned_models, prefixes, queries, \"activation\", \"continuation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['finetuned-1-l2_curvature-768x12', 'finetuned-1-l1_curvature-768x12', 'huggingface-pretrained-768x12', 'finetuned-1-l0_curvature-768x12'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprisal_dict = torch.load(\"/om2/user/jackking/modular_transformers/modular_transformers/train/surprisal_dict.pt\", map_location=torch.device('cpu'))\n",
    "surprisal_dict[\"activation\"][\"continuation\"].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
