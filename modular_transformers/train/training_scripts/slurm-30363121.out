/om2/user/jackking/anaconda/envs/mod_tran/bin/python
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Traceback (most recent call last):
  File "/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py", line 82, in <module>
    accelerator = Accelerator(log_with="wandb",gradient_accumulation_steps=gradient_accumulation_steps)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 346, in __init__
    self.state = AcceleratorState(
                 ^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/state.py", line 540, in __init__
    PartialState(cpu, **kwargs)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/state.py", line 124, in __init__
    torch.cuda.set_device(self.device)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/cuda/__init__.py", line 350, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

gpt2 size: 0.4M parameters
wandb: ERROR api_key not configured (no-tty). call wandb.login(key=[your_api_key])
Traceback (most recent call last):
  File "/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py", line 91, in <module>
    accelerator.init_trackers("bplm_gpt2", config=train_config,init_kwargs={'name':run_name})
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 548, in _inner
    return PartialState().on_main_process(function)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 2034, in init_trackers
    self.trackers.append(tracker_init(project_name, **init_kwargs.get(str(tracker), {})))
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/tracking.py", line 85, in execute_on_main_process
    return function(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/tracking.py", line 277, in __init__
    self.run = wandb.init(project=self.run_name, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/wandb/sdk/wandb_init.py", line 1164, in init
    raise e
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/wandb/sdk/wandb_init.py", line 1141, in init
    wi.setup(kwargs)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/wandb/sdk/wandb_init.py", line 289, in setup
    wandb_login._login(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/wandb/sdk/wandb_login.py", line 298, in _login
    wlogin.prompt_api_key()
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/wandb/sdk/wandb_login.py", line 228, in prompt_api_key
    raise UsageError("api_key not configured (no-tty). call " + directive)
wandb.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])
Using /home/jackking/.cache/torch_extensions/py311_cu117 as PyTorch extensions root...
Creating extension directory /home/jackking/.cache/torch_extensions/py311_cu117/cpu_adam...
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py:366: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++ 4.8.5) may be ABI-incompatible with PyTorch!
Please use a compiler that is ABI-compatible with GCC 5.0 and above.
See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.

See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6
for instructions on how to install GCC 5 or higher.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
Detected CUDA files, patching ldflags
Emitting ninja build file /home/jackking/.cache/torch_extensions/py311_cu117/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/TH -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/THC -isystem /cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++14 -g -Wno-reorder -L/cm/shared/openmind8/cuda/11.7/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
FAILED: cpu_adam.o 
c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/TH -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/THC -isystem /cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++14 -g -Wno-reorder -L/cm/shared/openmind8/cuda/11.7/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
c++: error: unrecognized command line option ‘-std=c++17’
c++: error: unrecognized command line option ‘-std=c++14’
[2/3] /cm/shared/openmind8/cuda/11.7/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/TH -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/THC -isystem /cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o 
FAILED: custom_cuda_kernel.cuda.o 
/cm/shared/openmind8/cuda/11.7/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/TH -isystem /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/THC -isystem /cm/shared/openmind8/cuda/11.7/include -isystem /om2/user/jackking/anaconda/envs/mod_tran/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o 
nvcc warning : The -std=c++14 flag is not supported with the configured host compiler. Flag will be ignored.
In file included from /usr/include/c++/4.8.2/cstdint:35:0,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/context.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:16,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:
/usr/include/c++/4.8.2/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support is currently experimental, and must be enabled with the -std=c++11 or -std=gnu++11 compiler options.
 #error This file requires compiler and library support for the \
  ^
In file included from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/core/ATenGeneral.h:3:0,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:13,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/context.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:16,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/macros/Macros.h:138:20: error: missing binary operator before token "("
 #if __has_attribute(used)
                    ^
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/macros/Macros.h:218:22: error: missing binary operator before token "("
 #elif __has_attribute(always_inline) || defined(__GNUC__)
                      ^
In file included from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/string_view.h:4:0,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/StringUtil.h:6,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/Exception.h:6,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/Context.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:14,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/context.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:16,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:16:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 5 or later."
 #error \
  ^
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:27:2: error: #error You need C++14 to compile PyTorch
 #error You need C++14 to compile PyTorch
  ^
In file included from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/Exception.h:7:0,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/Context.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:14,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/context.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:16,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/variant.h:243:2: error: #error "MPark.Variant requires C++11 support."
 #error "MPark.Variant requires C++11 support."
  ^
In file included from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/typeid.h:25:0,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/core/ScalarTypeToTypeMeta.h:5,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/core/TensorOptions.h:10,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/core/TensorImpl.h:11,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/core/GeneratorImpl.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/core/Generator.h:22,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/Context.h:3,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:14,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/context.h:8,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:16,
                 from /om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:
/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/include/c10/util/TypeIndex.h:81:2: error: #error "You're running a too old version of GCC. We need GCC 5 or later."
 #error "You're running a too old version of GCC. We need GCC 5 or later."
  ^
ninja: build stopped: subcommand failed.
Traceback (most recent call last):
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1893, in _run_ninja_build
    subprocess.run(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py", line 145, in <module>
    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
                                                                        ^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 1118, in prepare
    result = self._prepare_deepspeed(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 1409, in _prepare_deepspeed
    optimizer = DeepSpeedCPUAdam(optimizer.param_groups, **defaults)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
    self.ds_opt_adam = CPUAdamBuilder().load()
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 445, in load
    return self.jit_load(verbose)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 480, in jit_load
    op_module = load(name=self.name,
                ^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1284, in load
    return _jit_compile(
           ^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1509, in _jit_compile
    _write_ninja_file_and_build_library(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1624, in _write_ninja_file_and_build_library
    _run_ninja_build(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1909, in _run_ninja_build
    raise RuntimeError(message) from e
RuntimeError: Error building extension 'cpu_adam'
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187223 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 187222) of binary: /om2/user/jackking/anaconda/envs/mod_tran/bin/python
Traceback (most recent call last):
  File "/om2/user/jackking/anaconda/envs/mod_tran/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/launch.py", line 908, in launch_command
    deepspeed_launcher(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/launch.py", line 647, in deepspeed_launcher
    distrib_run.run(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-04-24_23:58:24
  host      : node094.ib.cluster
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 187224)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-24_23:58:24
  host      : node094.ib.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 187222)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
