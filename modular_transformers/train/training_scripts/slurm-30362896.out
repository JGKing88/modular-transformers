/om2/user/jackking/anaconda/envs/mod_tran/bin/python
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 1.58MB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.79MB/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.76MB/s]
Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]
Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 8.89MB/s]Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 8.81MB/s]
Traceback (most recent call last):
  File "/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py", line 82, in <module>
    accelerator = Accelerator(log_with="wandb",gradient_accumulation_steps=gradient_accumulation_steps)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/accelerator.py", line 346, in __init__
    self.state = AcceleratorState(
                 ^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/state.py", line 540, in __init__
    PartialState(cpu, **kwargs)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/state.py", line 124, in __init__
    torch.cuda.set_device(self.device)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/cuda/__init__.py", line 350, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

gpt2 size: 0.4M parameters
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 159797 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 159798 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 2 (pid: 159799) of binary: /om2/user/jackking/anaconda/envs/mod_tran/bin/python
Traceback (most recent call last):
  File "/om2/user/jackking/anaconda/envs/mod_tran/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/launch.py", line 908, in launch_command
    deepspeed_launcher(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/accelerate/commands/launch.py", line 647, in deepspeed_launcher
    distrib_run.run(args)
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/jackking/anaconda/envs/mod_tran/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/om2/user/jackking/modular_transformers//modular_transformers/train/accelerate_train_gpt2.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-24_23:45:25
  host      : node094.ib.cluster
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 159799)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
